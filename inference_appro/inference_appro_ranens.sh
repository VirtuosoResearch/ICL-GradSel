# python inference_appro_ranens.py --k 1 --model meta-llama/Llama-3.2-1B --task coin_flip
# python inference_appro_ranens.py --k 2 --model meta-llama/Llama-3.2-1B --task coin_flip
# python inference_appro_ranens.py --k 3 --model meta-llama/Llama-3.2-1B --task coin_flip
# python inference_appro_ranens.py --k 4 --model meta-llama/Llama-3.2-1B --task coin_flip
# python inference_appro_ranens.py --k 5 --model meta-llama/Llama-3.2-1B --task coin_flip
# python inference_appro_ranens.py --k 6 --model meta-llama/Llama-3.2-1B --task coin_flip

# # python inference_appro_ranens.py --k 1 --model facebook/opt-1.3b --task coin_flip
# # python inference_appro_ranens.py --k 2 --model facebook/opt-1.3b --task coin_flip
# # python inference_appro_ranens.py --k 3 --model facebook/opt-1.3b --task coin_flip
# # python inference_appro_ranens.py --k 4 --model facebook/opt-1.3b --task coin_flip
# # python inference_appro_ranens.py --k 5 --model facebook/opt-1.3b --task coin_flip

# # python inference_appro_ranens.py --k 1 --model meta-llama/Llama-3.2-3B --task coin_flip
# python inference_appro_ranens.py --k 2 --model meta-llama/Llama-3.2-3B --task coin_flip
# python inference_appro_ranens.py --k 3 --model meta-llama/Llama-3.2-3B --task coin_flip
# python inference_appro_ranens.py --k 4 --model meta-llama/Llama-3.2-3B --task coin_flip
# python inference_appro_ranens.py --k 5 --model meta-llama/Llama-3.2-3B --task coin_flip
# python inference_appro_ranens.py --k 6 --model meta-llama/Llama-3.2-3B --task coin_flip

# # python inference_appro_ranens.py --k 1 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip
# python inference_appro_ranens.py --k 2 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip
# python inference_appro_ranens.py --k 3 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip
# python inference_appro_ranens.py --k 4 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip
# python inference_appro_ranens.py --k 5 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip
# python inference_appro_ranens.py --k 6 --model deepseek-ai/deepseek-llm-7b-chat --task coin_flip

# # python inference_appro_ranens.py --k 1 --model meta-llama/Llama-3.1-8B --task coin_flip
# python inference_appro_ranens.py --k 2 --model meta-llama/Llama-3.1-8B --task coin_flip
# python inference_appro_ranens.py --k 3 --model meta-llama/Llama-3.1-8B --task coin_flip
# python inference_appro_ranens.py --k 4 --model meta-llama/Llama-3.1-8B --task coin_flip
# python inference_appro_ranens.py --k 5 --model meta-llama/Llama-3.1-8B --task coin_flip
# python inference_appro_ranens.py --k 6 --model meta-llama/Llama-3.1-8B --task coin_flip

# # python inference_appro_ranens.py --k 1 --model meta-llama/Llama-2-13b-hf --task coin_flip
# python inference_appro_ranens.py --k 2 --model meta-llama/Llama-2-13b-hf --task coin_flip
# python inference_appro_ranens.py --k 3 --model meta-llama/Llama-2-13b-hf --task coin_flip
# python inference_appro_ranens.py --k 4 --model meta-llama/Llama-2-13b-hf --task coin_flip
# python inference_appro_ranens.py --k 5 --model meta-llama/Llama-2-13b-hf --task coin_flip
# python inference_appro_ranens.py --k 6 --model meta-llama/Llama-2-13b-hf --task coin_flip

# python inference_appro_ranens.py --k 1 --model meta-llama/CodeLlama-34b-hf --task coin_flip
# python inference_appro_ranens.py --k 2 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 3 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 4 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 5 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 1 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 6 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 7 --model meta-llama/CodeLlama-34b-hf --task coin_flip
python inference_appro_ranens.py --k 8 --model meta-llama/CodeLlama-34b-hf --task coin_flip

